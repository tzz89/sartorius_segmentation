{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Model deployment\nIn this notebook, we will be converting the trained detectron2 model using torchscript and deploying the model on a inference server\n#### Steps required\n1. loading model\n2. run torchscript\n3. export model\n4. deployment on torchscript\n5. inference using rest/gRPC\n6. Try repeating with triton inference server\n\n## Reference\nhttps://github.com/facebookresearch/detectron2/tree/main/tools/deploy","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/facebookresearch/detectron2.git","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:08:47.464647Z","iopub.execute_input":"2022-02-01T08:08:47.464896Z","iopub.status.idle":"2022-02-01T08:08:49.744211Z","shell.execute_reply.started":"2022-02-01T08:08:47.464869Z","shell.execute_reply":"2022-02-01T08:08:49.743004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ./detectron2","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:08:49.746896Z","iopub.execute_input":"2022-02-01T08:08:49.747183Z","iopub.status.idle":"2022-02-01T08:11:08.169052Z","shell.execute_reply.started":"2022-02-01T08:08:49.747142Z","shell.execute_reply":"2022-02-01T08:11:08.168257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing required libraries","metadata":{}},{"cell_type":"code","source":"## python libraries\nimport os\nfrom typing import Dict ,List, Tuple\n\n## torch libraries\nimport torch\nfrom torch import Tensor, nn\n\n\n## detectron libraries\nfrom detectron2.config import get_cfg\nfrom detectron2.modeling import build_model, GeneralizedRCNN, RetinaNet\nfrom detectron2.model_zoo import get_config_file\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader, detection_utils\nfrom detectron2.utils.visualizer import Visualizer\nimport detectron2.data.transforms as T\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset, print_csv_format\nfrom detectron2.modeling.postprocessing import detector_postprocess\nfrom detectron2.structures import Boxes\nfrom detectron2.utils.env import TORCH_VERSION\nfrom detectron2.utils.file_io import PathManager\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.projects.point_rend import add_pointrend_config\nfrom detectron2.export import TracingAdapter, dump_torchscript_IR, scripting_with_instances\nfrom detectron2.utils.logger import setup_logger\n\n\n# image lib\nimport cv2\nimport matplotlib.pyplot as plt\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:11:08.17151Z","iopub.execute_input":"2022-02-01T08:11:08.171849Z","iopub.status.idle":"2022-02-01T08:11:09.61653Z","shell.execute_reply.started":"2022-02-01T08:11:08.171812Z","shell.execute_reply":"2022-02-01T08:11:09.615521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    model_zoo_model = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n    pretrained_model_weights = \"../input/satorius-train-detectron2-models/model_0007999.pth\"\n    \n    # roi heads\n    num_classes = 3\n    roi_head_batch_size_per_image =128\n    \n    #dataset\n    val_data = \"../input/satorius-segmentation-coco-json/val_coco.json\"\n    \n    #export params\n    output_fp = \"output\"\n    export_format = 'torchscript'","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:11:09.618515Z","iopub.execute_input":"2022-02-01T08:11:09.618766Z","iopub.status.idle":"2022-02-01T08:11:09.624768Z","shell.execute_reply.started":"2022-02-01T08:11:09.618736Z","shell.execute_reply":"2022-02-01T08:11:09.623129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# register train_data\n# register_coco_instances(CONFIG.train_dataset_name, {}, CONFIG.train_coco_json, CONFIG.image_root_dir)\n# register val data\n# register_coco_instances(CONFIG.val_dataset_name, {}, CONFIG.val_coco_json, CONFIG.image_root_dir)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T04:09:43.234737Z","iopub.execute_input":"2022-01-31T04:09:43.236768Z","iopub.status.idle":"2022-01-31T04:09:43.246717Z","shell.execute_reply.started":"2022-01-31T04:09:43.236698Z","shell.execute_reply":"2022-01-31T04:09:43.245828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## setup config\ncfg = get_cfg()\ncfg.merge_from_file(get_config_file(CONFIG.model_zoo_model))\ncfg.MODEL.DEVICE='cpu' \ncfg.MODEL.WEIGHTS = CONFIG.pretrained_model_weights\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = CONFIG.num_classes\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = CONFIG.roi_head_batch_size_per_image\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n\n# dataset config\ncfg.INPUT.MASK_FORMAT = 'bitmask'\n# cfg.DATASETS.TRAIN = (CONFIG.train_dataset_name,)\n# cfg.DATASETS.TEST = (CONFIG.val_dataset_name,)\ncfg.DATALOADER.NUM_WORKERS = 0\n\n#test config\ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\n\n#pointrend\nadd_pointrend_config(cfg)\n\ncfg.freeze()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:11:09.625957Z","iopub.execute_input":"2022-02-01T08:11:09.626207Z","iopub.status.idle":"2022-02-01T08:11:09.656247Z","shell.execute_reply.started":"2022-02-01T08:11:09.626179Z","shell.execute_reply":"2022-02-01T08:11:09.655416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## build model and load in weights\nmodel = build_model(cfg)\nDetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\nmodel.to(\"cpu\") # making sure its a cpu model\nmodel.eval();","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:11:09.659966Z","iopub.execute_input":"2022-02-01T08:11:09.660563Z","iopub.status.idle":"2022-02-01T08:11:16.473498Z","shell.execute_reply.started":"2022-02-01T08:11:09.660524Z","shell.execute_reply":"2022-02-01T08:11:16.472514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MetadataCatalog.get(\"../input/satorius-segmentation-coco-json/val_coco.json\")\n\nimg = cv2.imread(\"../input/sartorius-cell-instance-segmentation/train/0140b3c8f445.png\")\nheight, width = img.shape[:2]\naug = T.ResizeShortestEdge([cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST)\nimage = aug.get_transform(img).apply_image(img)\nimage = torch.as_tensor(image.astype(\"float32\").transpose(2,0,1)) #CHW as per pytorch\nsample_inputs = [{\"image\": image, \"height\": height, \"width\": width}]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T08:11:16.474987Z","iopub.execute_input":"2022-02-01T08:11:16.475299Z","iopub.status.idle":"2022-02-01T08:11:16.534973Z","shell.execute_reply.started":"2022-02-01T08:11:16.475257Z","shell.execute_reply":"2022-02-01T08:11:16.534093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model forward pass","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    model_output = model(sample_inputs)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T14:23:51.148405Z","iopub.execute_input":"2022-01-30T14:23:51.148834Z","iopub.status.idle":"2022-01-30T14:23:56.218465Z","shell.execute_reply.started":"2022-01-30T14:23:51.148801Z","shell.execute_reply":"2022-01-30T14:23:56.217822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v = Visualizer(img[:,:,::-1], MetadataCatalog.get(CONFIG.val_data), scale=1.2)\nout = v.draw_instance_predictions(model_output[0]['instances'].to('cpu'))\nplt.figure(figsize=(20,15))\nplt.imshow(out.get_image()[:,:,::-1])","metadata":{"execution":{"iopub.status.busy":"2022-01-30T14:24:05.245465Z","iopub.execute_input":"2022-01-30T14:24:05.245753Z","iopub.status.idle":"2022-01-30T14:24:06.69386Z","shell.execute_reply.started":"2022-01-30T14:24:05.245725Z","shell.execute_reply":"2022-01-30T14:24:06.692925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## After we have verify the model, we can export the model","metadata":{}},{"cell_type":"code","source":"def export_tracing(torch_model, inputs):\n    assert TORCH_VERSION >= (1, 8)\n    image = inputs[0][\"image\"]\n    inputs = [{\"image\": image}]  # remove other unused keys\n\n    if isinstance(torch_model, GeneralizedRCNN):\n\n        def inference(model, inputs):\n            # use do_postprocess=False so it returns ROI mask\n            inst = model.inference(inputs, do_postprocess=False)[0]\n            return [{\"instances\": inst}]\n\n    else:\n        inference = None  # assume that we just call the model directly\n\n    traceable_model = TracingAdapter(torch_model, inputs, inference)\n\n    if CONFIG.export_format == \"torchscript\":\n        ts_model = torch.jit.trace(traceable_model, (image,))\n        with PathManager.open(\"./output/model_cpu.pt\", \"wb\") as f:\n            torch.jit.save(ts_model, f)\n        dump_torchscript_IR(ts_model, CONFIG.output_fp)\n    elif CONFIG.export_format == \"onnx\":\n        with PathManager.open(os.path.join(CONFIG.output_fp, \"model.onnx\"), \"wb\") as f:\n            torch.onnx.export(traceable_model, (image,), f, opset_version=11)\n    logger.info(\"Inputs schema: \" + str(traceable_model.inputs_schema))\n    logger.info(\"Outputs schema: \" + str(traceable_model.outputs_schema))\n\n    if CONFIG.export_format != \"torchscript\":\n        return None\n    if not isinstance(torch_model, (GeneralizedRCNN, RetinaNet)):\n        return None\n\n    def eval_wrapper(inputs):\n        \"\"\"\n        The exported model does not contain the final resize step, which is typically\n        unused in deployment but needed for evaluation. We add it manually here.\n        \"\"\"\n        input = inputs[0]\n        instances = traceable_model.outputs_schema(ts_model(input[\"image\"]))[0][\"instances\"]\n        postprocessed = detector_postprocess(instances, input[\"height\"], input[\"width\"])\n        return [{\"instances\": postprocessed}]\n\n    return eval_wrapper","metadata":{"execution":{"iopub.status.busy":"2022-01-30T13:53:40.424492Z","iopub.execute_input":"2022-01-30T13:53:40.424938Z","iopub.status.idle":"2022-01-30T13:53:40.438129Z","shell.execute_reply.started":"2022-01-30T13:53:40.424898Z","shell.execute_reply":"2022-01-30T13:53:40.437184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"args \n1. format - torchscript\n2. export-method - tracing\n3. config-file - path to config file\n4. sample-image - default None\n5. run-eval - True/False\n6. output - output directory\n","metadata":{}},{"cell_type":"code","source":"os.makedirs(CONFIG.output_fp, exist_ok=True)\nlogger = setup_logger()\nexported_model = export_tracing(model, sample_inputs)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T13:53:41.284629Z","iopub.execute_input":"2022-01-30T13:53:41.28558Z","iopub.status.idle":"2022-01-30T13:54:08.003796Z","shell.execute_reply.started":"2022-01-30T13:53:41.285534Z","shell.execute_reply":"2022-01-30T13:54:08.00296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /output_cpu","metadata":{"execution":{"iopub.status.busy":"2022-01-30T13:46:51.727261Z","iopub.execute_input":"2022-01-30T13:46:51.727619Z","iopub.status.idle":"2022-01-30T13:46:52.550138Z","shell.execute_reply.started":"2022-01-30T13:46:51.727583Z","shell.execute_reply":"2022-01-30T13:46:52.549233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## zipping and exporting","metadata":{}},{"cell_type":"code","source":"!zip -r sartorius_torchscript.zip ./output","metadata":{"execution":{"iopub.status.busy":"2022-01-30T14:29:30.409438Z","iopub.execute_input":"2022-01-30T14:29:30.409773Z","iopub.status.idle":"2022-01-30T14:30:02.950285Z","shell.execute_reply.started":"2022-01-30T14:29:30.40973Z","shell.execute_reply":"2022-01-30T14:30:02.949163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reloading torchscript and testing\n\nImportant thing to take note is that image have been resized to [800, 1083]\n\n1. index 0 is the bbox (need to reshape)\n2. index 1 is the prediction class\n3. index 2 is the mask (Only the raw output, no postprocessing. only the 28x 28 mask is given, the mask have to be reshaped to the bbox size)\n4. index 3 is the confidence\n5. index 4 is the image size","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image, ImageDraw\nimport  matplotlib.pyplot as plt\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:23:20.316873Z","iopub.execute_input":"2022-02-01T10:23:20.317231Z","iopub.status.idle":"2022-02-01T10:23:20.321359Z","shell.execute_reply.started":"2022-02-01T10:23:20.317195Z","shell.execute_reply":"2022-02-01T10:23:20.320707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.jit.load(\"../input/sartorius-torchscripted/model_cpu.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:11:16.542072Z","iopub.execute_input":"2022-02-01T08:11:16.542721Z","iopub.status.idle":"2022-02-01T08:11:18.671564Z","shell.execute_reply.started":"2022-02-01T08:11:16.542676Z","shell.execute_reply":"2022-02-01T08:11:18.670664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image = Image.open(\"../input/sartorius-cell-instance-segmentation/train/0140b3c8f445.png\")\npil_image = np.array(raw_image)\nrgb_image = np.stack([pil_image,pil_image,pil_image],axis=2)\n\naug = T.ResizeShortestEdge([cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST)\naugmentation = aug.get_transform(np.stack([rgb_image,rgb_image],axis=-1))\nimage = augmentation.apply_image(rgb_image)\nimage = torch.as_tensor(image.astype(\"float32\").transpose(2,0,1)) #CHW as per pytorch","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:36:16.158665Z","iopub.execute_input":"2022-02-01T08:36:16.159159Z","iopub.status.idle":"2022-02-01T08:36:16.204799Z","shell.execute_reply.started":"2022-02-01T08:36:16.159121Z","shell.execute_reply":"2022-02-01T08:36:16.203985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    model_output = model(image)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:50:49.238873Z","iopub.execute_input":"2022-02-01T08:50:49.239707Z","iopub.status.idle":"2022-02-01T08:50:54.805021Z","shell.execute_reply.started":"2022-02-01T08:50:49.239668Z","shell.execute_reply":"2022-02-01T08:50:54.804168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inverse_augmentation = augmentation.inverse()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T09:59:59.825495Z","iopub.execute_input":"2022-02-01T09:59:59.826459Z","iopub.status.idle":"2022-02-01T09:59:59.830679Z","shell.execute_reply.started":"2022-02-01T09:59:59.826411Z","shell.execute_reply":"2022-02-01T09:59:59.82987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bboxes = inverse_augmentation.apply_box(model_output[0].detach())\nmasks = model_output[2].detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:00:00.860019Z","iopub.execute_input":"2022-02-01T10:00:00.860455Z","iopub.status.idle":"2022-02-01T10:00:00.866062Z","shell.execute_reply.started":"2022-02-01T10:00:00.8604Z","shell.execute_reply":"2022-02-01T10:00:00.865343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rgbimg = Image.new(\"RGBA\",raw_image.size)\nrgbimg.paste(raw_image)\noriginal_rgbimg = rgbimg.copy()\noriginal_rgbimg.putalpha(160)\ndraw = ImageDraw.Draw(rgbimg)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:35:57.745372Z","iopub.execute_input":"2022-02-01T10:35:57.745661Z","iopub.status.idle":"2022-02-01T10:35:57.75388Z","shell.execute_reply.started":"2022-02-01T10:35:57.745631Z","shell.execute_reply":"2022-02-01T10:35:57.753275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for bbox, mask in zip(bboxes, masks):\n    random_hex = \"#\"+''.join([random.choice('ABCDEF0123456789') for i in range(6)])\n    draw.rectangle(\n                    [int(coord) for coord in bbox],\n                    width=1,\n                    outline=random_hex\n                  )\n    bbox_width = int(bbox[2]-bbox[0])\n    bbox_height = int(bbox[3] - bbox[1])\n    \n    mask_map = Image.fromarray(np.squeeze(mask), mode='F')\n    mask_map = mask_map.resize((bbox_width, bbox_height), resample=Image.BILINEAR)\n    mask_map_array = np.array(mask_map) > 0.5\n    mask_map = Image.fromarray(mask_map_array)\n\n    draw.bitmap((int(bbox[0]), int(bbox[1])), mask_map, fill=random_hex)\n    \n    \nrgbimg.putalpha(128)\ncombined_image = Image.alpha_composite(original_rgbimg, rgbimg)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:35:57.941655Z","iopub.execute_input":"2022-02-01T10:35:57.942148Z","iopub.status.idle":"2022-02-01T10:35:57.96485Z","shell.execute_reply.started":"2022-02-01T10:35:57.9421Z","shell.execute_reply":"2022-02-01T10:35:57.964161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:56:32.153369Z","iopub.execute_input":"2022-02-01T10:56:32.153712Z","iopub.status.idle":"2022-02-01T10:56:32.263537Z","shell.execute_reply.started":"2022-02-01T10:56:32.15368Z","shell.execute_reply":"2022-02-01T10:56:32.262618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_image","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:36:02.772103Z","iopub.execute_input":"2022-02-01T10:36:02.772376Z","iopub.status.idle":"2022-02-01T10:36:02.937432Z","shell.execute_reply.started":"2022-02-01T10:36:02.772348Z","shell.execute_reply":"2022-02-01T10:36:02.93642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding to base64","metadata":{}},{"cell_type":"code","source":"import io","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:38:50.269586Z","iopub.execute_input":"2022-02-01T10:38:50.269952Z","iopub.status.idle":"2022-02-01T10:38:50.274555Z","shell.execute_reply.started":"2022-02-01T10:38:50.269902Z","shell.execute_reply":"2022-02-01T10:38:50.273762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buffer = io.BytesIO()\ncombined_image.save(buffer, format='png')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:44:26.510274Z","iopub.execute_input":"2022-02-01T10:44:26.510594Z","iopub.status.idle":"2022-02-01T10:44:26.670126Z","shell.execute_reply.started":"2022-02-01T10:44:26.510561Z","shell.execute_reply":"2022-02-01T10:44:26.669035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buffer.getvalue()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:44:29.072981Z","iopub.execute_input":"2022-02-01T10:44:29.073257Z","iopub.status.idle":"2022-02-01T10:44:29.103737Z","shell.execute_reply.started":"2022-02-01T10:44:29.073228Z","shell.execute_reply":"2022-02-01T10:44:29.102974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buffer.getbuffer()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T10:42:56.971219Z","iopub.execute_input":"2022-02-01T10:42:56.971493Z","iopub.status.idle":"2022-02-01T10:42:56.992534Z","shell.execute_reply.started":"2022-02-01T10:42:56.971465Z","shell.execute_reply":"2022-02-01T10:42:56.9912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}